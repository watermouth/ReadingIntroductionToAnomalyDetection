---
title: "Chapter3"
output: html_document
---

# 非正規分布に従うデータからの異常検知

正常データの分布のモデルを1つの正規分布で近似するのが不適切な場合にどうするか。

## 分布が左右対称でない場合  
1次元のデータが全て非負の値をとるとき、ガンマ分布によるモデル化を行うと良い場合がある。

### ガンマ分布とカイ2乗分布
ガンマ分布は、次の密度関数を持つ分布である。
\[ \mathcal{G}(x|k,s) = \frac{1}{s\varGamma (k)}\left(\frac{x}{s}\right)^{k-1} \exp\left(-\frac{x}{s}\right) \]

同じ事だが、$s$の逆数をパラメータとして次のような形で書いてある文献もある。
\[ \mathcal{\tilde{G}}(x|a,b) = \frac{b^a}{\varGamma (a)} x^{a-1} \exp\left(-bx \right) \]

自由度$k$, スケール因子$s$のカイ2乗分布の別の表現ともいえる;
\[ \chi (k,s) = \varGamma(\frac{k}{2}, 2s) \]

### ガンマ分布$\mathcal{G}(k,s)$のパラメータ$k, s$の推定

* 最尤推定
正規分布のパラメータ推定を行う際に最尤推定を用いた。
もちろんガンマ分布でも最尤推定することができるが、
正規分布と違って閉じた解として求めることができない。
そこで、対数尤度を数値的に最大化することで、最尤推定量を求める。  
Rのfitdistr関数を使うと、典型的な1次元確率分布の最尤推定を行うことができる。       


```{r }
library(car)
data(Davis)
X <- Davis
xmin <- min(X$weight)-10
xmax <- max(X$weight)+10
library(MASS)
fit.obj <- fitdistr(x = X$weight, densfun = "gamma")
kml <- fit.obj$estimate[["shape"]]
sml <- 1 / fit.obj$estimate[["rate"]]
```

$k=`r kml`$, $s=`r sml`$

* モーメント法(Method of moments) 
分布のモーメントを母数を用いて求め、分布のモーメントを標本から推定することで、母数の推定を行う。
    + 最尤推定と違って閉じた形で求めることができる（常にできるかどうかは不明）
    + 一般に偏りのある推定量である
    + 数値的に最尤推定を行う際の初期値を求めることに使える
    + Generalized method of moments(GMM)はMethod of momentsの一般化  
      semiparametric modelの推定に使うらしい（だれかやって下さい）

ガンマ分布のパラメータ$k,s$はそれぞれ、標本平均$\hat{\mu}$,標本分散$\hat{\sigma}^2$を用いて、
$k_{mo} = \frac{(\hat{\mu})^2}{\hat{\sigma}^2}, s_{mo} = \frac{\hat{\sigma}^2}{\hat{\mu}}$ 
として求めることができる。

```{r}
N <- nrow(X)
mu <- mean(X$weight)
sigma2 <- var(X$weight) * (N - 1) / N 
kmo <- mu^2 / sigma2
smo <- sigma2 / mu
# テキストでは下のようにしているが、求める物が微妙に間違っている
# si <- sd(X$weight) * (N-1)/N
# kmo <- mu^2 / si^2 
# smo <- si^2 / mu
```

$k=`r kmo`$, $s=`r smo`$

プロットすると次のようになる。

```{r}
hist(X$weight, breaks=10, xlim=c(xmin, xmax))
x <- seq(0, max(X$weight), by=1)
y <- dgamma(x=x, shape = kml, scale = sml)
par(new=T)
plot(x, y, xlim=c(xmin, xmax), type="l", col="red", ylab = "", xlab = "", axes = F)
y <- dgamma(x=x, shape = kmo, scale = smo)
par(new=T)
plot(x, y, xlim=c(xmin, xmax), type="l", col="grey", lty=2, ylab = "", xlab="", axes = F)
```

### 異常度
いつものように$-\ln p(x^{'})$で定義する。$x^{'}$に依存しない部分は除いて定義しておく;
\[a(x^{'}) = \frac{x^{'}}{\hat{s}} - (\hat{k} - 1)\ln \frac{x^{'}}{\hat{s}} \]  

```{r}
k <- kmo
s <- smo
a <- X$weight / s - (k - 1) * log(x = X$weight / s)
th.idx <- order(a, decreasing = T)[0.01*N]
th <- a[th.idx]
anomaly.points <- which(a > th)
plot(a, xlab="index", ylab="anomaly score")
lines(1:N, rep(th,N), lty=2, col="red")
```

* 赤の点線は99%点を表す。この例では200点データがあるから、2番目に異常な点となる。  
このように異常度の分布が明示的に分からない場合は、閾値として正常(と信じられる)データの分位点を用いる。

ついでに最尤推定量を用いた場合も描いておく。
```{r}
k <- kml
s <- sml
a <- X$weight / s - (k - 1) * log(x = X$weight / s)
th.idx <- order(a, decreasing = T)[0.01*N]
th <- a[th.idx]
anomaly.points <- which(a > th)
plot(a, xlab="index", ylab="anomaly score")
lines(1:N, rep(th,N), lty=2, col="red")
```

## カイ2乗分布による異常度の当てはめ

実データの分布をじゅうぶん正規分布で近似できないとき、
異常度の分布を自由度Mのカイ2乗分布分布であると見做すと、
異常と見做されるケースが多くなりがち、らしい。

### FXプライス(USDJPY)の階差系列の正規性と異常度

USDJPYプライスの階差系列が正規分布に従うと見做して異常検知をしてみる。
正規分布からサンプリングした値と比較しながらみてみよう。

```{r, cache=TRUE}
library(quantmod)
getFX(Currencies = "USD/JPY", from = as.Date("2015-01-01"), to = as.Date("2015-12-31"))
plot(USDJPY)
x2 <- as.numeric(USDJPY)
x2 <- diff(x2)
x2 <- (x2 - mean(x2)) / sd(x2)
count <- length(x2)
x1 <- rnorm(n = count, mean = 0, sd = 1)
```

用意したデータのNormal q-q plot

正規分布に従う変数であるならば点が直線上に乗る。

* x1 : 標準正規分布からサンプリング
* x2 : プライス階差系列を平均0,分散1に標準化（比較しやすくするため）したもの

```{r}
qqnorm(x1, ylim = c(-4,4)); qqline(x1); title(sub = "x1")
qqnorm(x2, ylim = c(-4,4)); qqline(x2); title(sub = "x2")
```

x1に比べると、x2はあまり直線上に乗っていないことが分かる。

さて、異常度を求めて、閾値を1%に定めて検知してみる。

```{r}
a1 <- (x1 - mean(x1)) ^ 2 / mean((x1-mean(x1))^2)
a2 <- (x2 - mean(x2)) ^ 2 / mean((x2-mean(x2))^2)
th <- qchisq(p=0.99, df=1)
a1_detected <- which(a1 > th)
a2_detected <- which(a2 > th)
```

サンプルサイズは`r count`、理論上は1% = `r count * 0.01`点が検知される。[^3.2.a]

このサンプルで検知された点の個数は次の通り;  
x1 : `r length(a1_detected)`, x2 : `r length(a2_detected)`

[^3.2.a]: より正確には、検知される点の割合$r$を分位点で定めているから、あるサンプルの点が検知される確率は$r$、検知されない確率は$1-r$である。つまり検知される点の個数は2項分布に従う。
サンプルサイズ$N$とすれば$Nr$=`r count * 0.01` 点が期待値、
標準偏差$\sqrt{Nr(1-r)}$=`r sqrt(count * 0.01 * (1-0.01))`である。

他の期間だったらどうか、一応確認しておこう。

```{r, cache=T}
source("section3.1.R")
ret <- compare_FX_price_diff_anomaly(
  start_date = as.Date("2008-01-01")
  , end_date = as.Date("2012-03-31"))
count <- ret$count
a1_detected <- which(ret$a1 > ret$th)
a2_detected <- which(ret$a2 > ret$th)
```

サンプルサイズは`r count`、理論上は1% = `r count * 0.01`点が検知される。

このサンプルで検知された点の個数は次の通り;  

x1 : `r length(a1_detected)`[^3.2.b], x2 : `r length(a2_detected)`

[^3.2.b]:標準偏差$\sqrt{Nr(1-r)}$=`r sqrt(count * 0.01 * (1-0.01))`

参考までに、

>2008年9月15日に、アメリカ合衆国の投資銀行であるリーマン・ブラザーズが破綻
>(https://ja.wikipedia.org/wiki/リーマン・ショック より)

を引用し、前日からのプライス階差系列について異常検知された日付とプライスをみておく。

```{r echo=F, results='asis'}
library(xtable)
output.file.type <- "html"
print(xtable(x = data.frame(ret$price[a2_detected]), caption = "USDJPY prices when there were anomaly price differences"), type = output.file.type, comment = FALSE)
```

```{r echo=F, results='asis'}
if(output.file.type == "latex"){
  cat("\\newpage")
}
```

### 本題

カイ二乗分布はガンマ分布なので、method of moments（積率法）により
自由度とスケール因子を求めることができる。

```{r}
a1 <- (x1 - mean(x1)) ^ 2 / mean((x1-mean(x1))^2)
a2 <- (x2 - mean(x2)) ^ 2 / mean((x2-mean(x2))^2)
f <- function(mean, variance){
  list(k=2*mean^2 / variance, s=variance / (2*mean))
}
count <- length(a1)
param1 <- f(mean(a1), var(a1) *(count - 1) / count)
param2 <- f(mean(a2), var(a2) *(count - 1) / count)
```

推定されたパラメータは次の表の通り;

データセット|自由度|スケール因子|
------------|------|-------------
x1（正規分布からのサンプル）|`r param1$k`|`r param1$s`
x2（プライス階差系列）|`r param2$k`|`r param2$s`

x1の自由度は1に近いが、x2つまりプライス階差の自由度はその半分程度である。

このようにして推定される自由度を有効次元(effective dimension)と呼ぶ。
次元$M$の多次元データの場合は実質的に効いていない次元があることにより、
有効次元のほうがぐっと小さくなるとのことである。
今回挙げた例は1次元データなので、この辺は確認出来ていない。

## クラスタリング

### 訓練データに異常標本が混ざっている場合

ある正規分布に従うと考えられるデータが局在していると同時に、
背景ノイズといえるデータが広がっているとする。たとえば、次の図に示すように
2つの1次元正規分布からサンプルされたデータがあるとする。

```{r }
#' 信号成分
mu0 <- 3; sig0 <- 0.5
#' 雑音成分
mu1 <- 0; sig1 <- 3
#' 割合
pi0 <- 0.6; pi1 <- 0.4

solutions <- list(pi=c(pi0,pi1), mu=c(mu0, mu1), sigma=c(sig0, sig1))

N <- 1000
attr <- sample(0:1,N,replace=T,prob=c(pi0,pi1))
x <- vector(mode = "numeric", length = N)
x[which(attr == 0)] <- rnorm(sum(attr == 0), mean = mu0, sd = sig0)
x[which(attr == 1)] <- rnorm(sum(attr == 1), mean = mu1, sd = sig1)
x0 <- x[which(attr == 0)]
x1 <- x[which(attr == 1)]

hist(x, breaks=100)
```

このような場合にそれぞれの分布と点の個数の割合を求める方法として、
Expectation-Maximization Algorhythm（EMアルゴリズム）が知られている。
これについては問題が複雑にならない範囲で一般化し次節で説明することとし、
ひとまずアルゴリズムと実行結果を以下に示す。

#### 1次元混合正規分布のEM法
 
$K$成分混合正規分布モデル
 
\[p(x) = \sum_{i=1}^{K} \pi_{i} N(x|\mu_i,\sigma_i^2) \]
 
parameter $\{ \pi_i, \mu_i, \sigma_i^2 \}_{i=1,...,K}$ を求める手順
 
1) $\{ \pi_i, \mu_i, \sigma_i^2 \}$の初期値を適当に与える。
 
2) データ$x^{(n)}$のi番目の正規分布への帰属度$q_i^{(n)}$を求める。
 
\[\displaystyle q_i^{(n)} = \frac{\pi_{i} N(x^{(n)}|\mu_i,\sigma_i^2)}{\sum_{i=1}^{K} \pi_{i} N(x^{(n)}|\mu_i,\sigma_i^2)}\]

3) $\{q_i^{(n)}\}_{i=1}^K$ から
 \par 
 $\displaystyle \mu_i = \frac{\sum_{n=1}^N q_i^{(n)} x^{(n)}}{\sum_{n=1}^N q_i^{(n)}}$,
 $\displaystyle \sigma_i ^2 = \frac{\sum_{n=1}^N q_i^{(n)} \left(x^{(n)}-\mu_i\right)^2}{\sum_{n=1}^N q_i^{(n)}}$,
 $\displaystyle \pi_i = \frac{1}{N}\sum_{n=1}^{N} q_i^{(n)}$
 
4) 値が収束していなければ2)に戻る.

```{r}
#' 1) 初期値
#' 変数名の0, 1は便宜上のものであり、各変数について求まった値が、正解の変数名に対する値とは限らない。今の例では2つの正規分布を仮定している。初期値の変数名中の0,1は、データxの分布0,1に対応するとは限らない。

pi0 <- 0.5; pi1 <- 0.5
mu0 <- -5; mu1 <- 5
sig0 <- 2; sig1 <- 2

iterLength <- 20
mu_iter <- matrix(nrow = iterLength, ncol = 2)
sigma_iter <- matrix(nrow = iterLength, ncol = 2)
pi_iter <- matrix(nrow = iterLength, ncol = 2)
for (iter in 1:iterLength){
  #　2) 帰属度の計算
  cprob0 <- dnorm(x = x, mean = mu0, sd = sig0)
  cprob1 <- dnorm(x = x, mean = mu1, sd = sig1)
  denom <-  (pi0 * cprob0 + pi1 * cprob1)
  q0 <- pi0 * cprob0 / denom
  q1 <- pi1 * cprob1 / denom
  #  3) パラメータ更新
  pi0 <- mean(q0)
  pi1 <- mean(q1)
  mu0 <- sum(q0 * x) / (N*pi0)
  mu1 <- sum(q1 * x) / (N*pi1)
  sig0 <- sqrt(sum(q0 * (x - mu0)^2) / (N*pi0))
  sig1 <- sqrt(sum(q1 * (x - mu1)^2) / (N*pi1))
  pi_iter[iter,] <- c(pi0,pi1)
  mu_iter[iter,] <- c(mu0,mu1)
  sigma_iter[iter,] <- c(sig0,sig1)
}
```

```{r results="asis"}
#' 逐次更新による求解の様子
targets <- list(pi_iter, mu_iter, sigma_iter)
target.names <- names(solutions)
for (i in seq(1,length(targets))){
  target <- targets[[i]]
  cat(paste0(target.names[i], "の収束の様子", "\n\n"))
  matplot(x = 1:iterLength, target, pch = c("0","1")
          , xlab = "iter", ylab = target.names[i])
  for (j in seq(1,length(solutions[[i]]))){
    abline(h = solutions[[i]][j], xlab = NULL, ylab = NULL)
  }
}
```

```{r echo=T}
#' 正常・異常モデルパラメータ
mu_iter[iterLength,]
sigma_iter[iterLength,]
#' 割合
pi_iter[iterLength,]
```

### K成分混合正規分布煮体するEMアルゴリズムによるパラメータ推定手続きの導出

データセット$\mathcal{D} = \{x^{(n)} \in R^M, n=1...N\}$
の各点が、$K$個の異なる正規分布のいずれかからサンプリングされたものであると仮定しよう。
各正規分布の平均と分散行列を表すパラメータを$(\mu_i, \Sigma _i), i=1,...,K$とする。

点$x$が$i$番目の正規分布に所属する点であることを
点$x$は$i$番目のクラスに属すと呼び、
点$x$が属すクラスを表す変数$z$を用いて$z=i$と表すことにすると、
条件付き確率密度について次のモデル化を行ったことになる。
\[p(x|z=i, \mu_i, \Sigma_i) = N(x|\mu_i, \Sigma_i)\]

一般の$z$の場合に次の形に書けることが重要である。
\[p(x|z, \{(\mu_i, \Sigma_i),i=1,...,K\})
 = \prod _{i=1}^{K} N(x|\mu_i, \Sigma_i) ^{\delta _{z,i}} \]
$\delta _{z,i}$は$z=i$のとき1, そうでないとき0を取る。

$x$の周辺密度は
\[p(x|\{(\mu_i, \Sigma_i),i=1,...,K\}) = \sum_{i=1}^K p(x|z=i, \mu_i, \Sigma_i)p(z=i)
= \sum_{i=1}^K \pi_i N(x|\mu_i, \Sigma_i)\]
ここで、$\pi_i := p(z=i)$であり$z$の事前確率（記号上紛らわしいが周辺確率ではない）である。

未知パラメータセット$\Theta := \{(\pi_i, \mu_i, \Sigma_i),i=1,...,K\}$
をどのように推定すると良いだろうか。

最尤推定で推定するため、対数尤度を求める;

\[L(\Theta | \mathcal{D})
= \ln \left[ \prod_{n=1}^{N} p(x^{(n)}|\Theta) \right]
= \ln \left[ \prod_{n=1}^{N} \sum_{i=1}^K \pi_i N(x^{(n)}|\mu_i, \Sigma_i) \right]
= \sum_{n=1}^{N} \ln \left[ \sum_{i=1}^K \pi_i N(x^{(n)}|\mu_i, \Sigma_i) \right]
\]

求めたいパラメータで偏微分を取って0とおいて素直に求められればよいのだが、難しそうである。
$K=1$であれば対数の中の和がないので、解析的に求める事ができたのだった(ホテリング理論の辺り)。

そこで対数尤度の形に着目すると、実はJensenの不等式が使える形になっている。

Jensenの不等式は、$f$を上に凸なR値関数、重み$a_i \ge 0 , i=1,...,K$, $\sum_i a_i = 1$とすると
\[ f(\sum_{i=1}^{K} a_i x_i) \ge \sum_{i=1}^{K} a_i f(x_i) \]
等号は$x_1=\cdots=x_N$のとき。

対数尤度中の対数関数と$\pi_i, i=1,\cdots,K$が$f$,
$a_i, i=1,\cdots,K$に対応していると見做せ、
Jensenの不等式の左辺=対数尤度そのものではなく、右辺を最大化することが考えられる。

しかしここでJensenの不等式の等号の条件からわかるように、
右辺が最大化されるのは全$i$について$\mu_i, \Sigma_i$が一致するという自明な解のときである。
クラスタリングを行いたいため、このような自明な解は避けたい。
そこで、$n$に依存する新たな重み$q_i^{(n)} \ge 0, \sum_{i=1}^{K}q_i^{(n)} = 1, \forall n$
を導入し、次のような不等式を得る。
\[ L(\Theta | \mathcal{D}) =  
  \sum_{n=1}^{N} \ln \left[ \sum_{i=1}^K q_i^{(n)} \frac{ \pi _i N(x^{(n)}|\mu_i, \Sigma_i) }{q_i^{(n)}} \right] \ge \sum_{n=1}^{N} \sum_{i=1}^K q_i^{(n)} \ln \left[ \frac{\pi_i N(x^{(n)}|\mu_i, \Sigma_i)}{q_i^{(n)}} \right]
\]

右辺を最大化する$q$はLagrangeの未定乗数法により求める事ができる;
\[
  q_i^{(n)} = \frac{\pi _i N(x^{(n)}|\mu_i, \Sigma_i)}{\sum_{i=1}^{K}\pi _i N(x^{(n)}|\mu_i, \Sigma_i)}
  = \frac{p(x|z=i, \mu_i, \Sigma_i)p(z=i)}{\sum_{i=1}^K p(x|z=i, \mu_i, \Sigma_i)p(z=i)}
  = p(z^{(n)}=i|x^{(n)}, \{(\mu_i, \Sigma_i),i=1,...,K\}).
\]
Jensenの不等式の等号の条件を満たす解であると同時に、クラス$z$の事後確率となっている。
$p(z=i|x) = E[\rm{I}_{\{z=i\}}|x]$より、$\mathcal{D}, \Theta$から求まる「期待値」ともいえる。

最適でないパラメータ$\Theta^{'}$に対して全$q_i^{(n)}$を求め、
$q_i^{(n)}$所与として

\[
 L(\Theta | \mathcal{D}) \ge g(\Theta|\Theta^{'}) := \sum_{n=1}^{N} \sum_{i=1}^K q_i^{(n)} \ln \left[ \frac{\pi_i N(x^{(n)}|\mu_i, \Sigma_i)}{q_i^{(n)}} \right]
\]

の$g(\Theta|\Theta^{'})$を「最大化」する$\Theta$を求める。
これは極値を求める通常の手続きにより求めることができる。
求まった$\Theta$を所与として再び$q_i^{(n)}$を求めるところから繰り返し、
$\Theta^{'}$と$\Theta$が十分収束したならば繰り返しをやめる。

このように「期待値」を求める手続きと「最大化」を行う手続きを繰り返すことで
最尤推定を行う事ができる。

「期待値」-「最大化」の繰り返しにより対数尤度の最大化ができることを見やすくするため、$l-1$番目の$\Theta=\Theta_{l-1}$を所与として$g(\Theta|\Theta_{l-1})$の最大化により求めた$\Theta$を$\Theta_l$と表すと、次の関係式が成立するということである。
\[
  L(\Theta_{l} | \mathcal{D}) \ge g(\Theta_{l}|\Theta_{l-1}) \ge g(\Theta_{l-1}|\Theta_{l-1}) =  L(\Theta_{l-1} | \mathcal{D}) 
\]

* 補足
実用上は初期値次第で推定がうまく行かないケースがあるらしい。
それを避けるため、$z$ではなく$\pi_i,i=1,\cdots,K$
に体する事前分布(Dirichlet分布)を仮定することでスムージングを行ったりするらしい。









```{r echo=F}
```
